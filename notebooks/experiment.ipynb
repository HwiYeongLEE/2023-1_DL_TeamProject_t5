{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Packages Installation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd /home/2023-1_DL_TeamProject_t5\n",
    "# %pip install -r requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Environment Variables Settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_PROJECT=DL2023_t5\n",
      "env: WANDB_NOTEBOOK_NAME=./experiment.ipynb\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_PROJECT=Comsmetics&Medicines_CORD_DLt5\n",
    "%env WANDB_NOTEBOOK_NAME=./experiment.ipynb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import re\n",
    "from nltk import edit_distance\n",
    "\n",
    "from util import LogPredictionsCallback\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "# from pytorch_lightning.utilities import rank_zero_only\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import (\n",
    "    DonutProcessor,\n",
    "    VisionEncoderDecoderConfig,\n",
    "    VisionEncoderDecoderModel,\n",
    "    get_scheduler\n",
    ")\n",
    "\n",
    "import wandb\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device.type"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter Settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'WORKING_DIR': \"/home/2023-1_DL_TeamProject_t5\",\n",
    "    'SEED':17,\n",
    "    'NUM_WORKERS':4,\n",
    "    'IMG_HEIGHT':800,\n",
    "    'IMG_WIDTH':600,\n",
    "    'MAX_LEN':1024,\n",
    "    'BATCH_SIZE':1,\n",
    "    'SAMPLING_RATE':1,\n",
    "    'VAL_SPLIT': 0.2,\n",
    "    'PIN_MEMORY': True,\n",
    "    'SWEEP_NUM': 6\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set Working Direcotry**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/2023-1_DL_TeamProject_t5\n"
     ]
    }
   ],
   "source": [
    "os.chdir(CFG['WORKING_DIR'])\n",
    "print(os.getcwd())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fix Seeds**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset Building & Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_dict = {0:\"uni\", 1:\"nm\", 2:\"ing\", 3:\"exp\", 4:\"how\", 5:\"des\", 9:\"etc\"}\n",
    "\n",
    "class DonutDataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataframe: pd.DataFrame,\n",
    "        max_length: int,\n",
    "        processor: DonutProcessor,\n",
    "        split: str = \"train\",\n",
    "        ignore_id: int = -100,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.max_length = max_length\n",
    "        self.split = split\n",
    "        self.ignore_id = ignore_id\n",
    "        self.dataframe = dataframe.reset_index(drop=True)\n",
    "        self.dataframe_length = len(self.dataframe)\n",
    "        self.processor = processor\n",
    "        self.gt_container = []\n",
    "        \n",
    "        for idx, sample in self.dataframe.iterrows():\n",
    "            ground_truth = self.get_gt_strings(eval(sample['texts']))\n",
    "            self.gt_container.append(ground_truth)\n",
    "\n",
    "    def get_gt_strings(self, ct):\n",
    "        \n",
    "        gt_string = \"\"\n",
    "        flag = 1\n",
    "        tp = -1\n",
    "        for i, item in enumerate(ct):\n",
    "            if flag:\n",
    "                gt_string = gt_string + f'<{type_dict[item[0]]}>'\n",
    "                tp = item[0]\n",
    "                flag = 0\n",
    "                gt_string = gt_string + f'{item[1]}'\n",
    "            \n",
    "            elif not flag:\n",
    "                gt_string = gt_string + f' {item[1]}'\n",
    "            \n",
    "            if i == len(ct)-1 or ct[i+1][0] != tp:\n",
    "                gt_string = gt_string + f'</{type_dict[item[0]]}>'\n",
    "                flag = 1\n",
    "        \n",
    "        return gt_string\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return self.dataframe_length\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "\n",
    "        sample = self.dataframe.loc[idx]\n",
    "        image = Image.open(sample['image_path'])\n",
    "       \n",
    "        pixel_values = self.processor(image, random_padding=self.split == \"train\", return_tensors=\"pt\").pixel_values.squeeze()\n",
    "\n",
    "        target_sequence = self.gt_container[idx] \n",
    "        input_ids = self.processor.tokenizer(\n",
    "            target_sequence,\n",
    "            add_special_tokens=False,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )[\"input_ids\"].squeeze(0)\n",
    "\n",
    "        labels = input_ids.clone()\n",
    "        labels[labels == self.processor.tokenizer.pad_token_id] = self.ignore_id  \n",
    "\n",
    "        return pixel_values, labels, target_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    }
   ],
   "source": [
    "processor = DonutProcessor.from_pretrained(\"naver-clova-ix/donut-base\")\n",
    "processor.image_processor.size = {\"height\": CFG['IMG_HEIGHT'],\"width\": CFG['IMG_WIDTH']}\n",
    "added_tokens = [fr'<{x}>' for x in type_dict.values()] + [fr'</{x}>' for x in type_dict.values()]\n",
    "processor.tokenizer.add_tokens(added_tokens)\n",
    "\n",
    "donut_config = VisionEncoderDecoderConfig.from_pretrained(\"naver-clova-ix/donut-base\")\n",
    "donut_config.encoder.image_size = [CFG['IMG_HEIGHT'], CFG['IMG_WIDTH']]\n",
    "donut_config.decoder.max_length = CFG['MAX_LEN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():    \n",
    "    model = VisionEncoderDecoderModel.from_pretrained(\"naver-clova-ix/donut-base\", config=donut_config, ignore_mismatched_sizes=True)\n",
    "    model.decoder.resize_token_embeddings(len(processor.tokenizer))\n",
    "    model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
    "    model.config.decoder_start_token_id = processor.tokenizer.convert_tokens_to_ids(['<s>'])[0]\n",
    "    return model\n",
    "\n",
    "model = model_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad token ID: <pad>\n",
      "Decoder start token ID: <s>\n"
     ]
    }
   ],
   "source": [
    "print(\"Pad token ID:\", processor.decode([model.config.pad_token_id]))\n",
    "print(\"Decoder start token ID:\", processor.decode([model.config.decoder_start_token_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_val_df = pd.read_csv(\"./dataframes/train_annot_df.csv\")\n",
    "# test_df = pd.read_csv(\"./dataframes/test_annot_df.csv\")\n",
    "\n",
    "train_df, val_df = train_test_split(train_val_df, test_size=CFG['VAL_SPLIT'], random_state=CFG['SEED'])\n",
    "\n",
    "train_df = train_df.sample(frac=CFG['SAMPLING_RATE'], random_state=CFG['SEED'], ignore_index=True)\n",
    "val_df = val_df.sample(frac=CFG['SAMPLING_RATE'], random_state=CFG['SEED'], ignore_index=True)\n",
    "\n",
    "train_dataset = DonutDataset(train_df, max_length=CFG['MAX_LEN'], processor=processor, split=\"train\")\n",
    "val_dataset = DonutDataset(val_df, max_length=CFG['MAX_LEN'], processor=processor, split=\"validation\")\n",
    "# test_dataset = DonutDataset(test_df, max_length=CFG['MAX_LEN'], processor=processor, split=\"test\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataloader Building**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True, num_workers=CFG['NUM_WORKERS'], pin_memory=CFG['PIN_MEMORY'])\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=CFG['NUM_WORKERS'], pin_memory=CFG['PIN_MEMORY'])\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=CFG['NUM_WORKERS'], pin_memory=CFG['PIN_MEMORY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 800, 600])\n"
     ]
    }
   ],
   "source": [
    "#Batch Verifying\n",
    "batch = next(iter(train_dataloader))\n",
    "pixel_values, labels, target_sequences = batch\n",
    "print(pixel_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<des>\n",
      "SO\n",
      "LU\n",
      "TION\n",
      "C\n",
      "ARE\n",
      "여\n",
      "드\n",
      "름\n",
      "성\n",
      "피\n",
      "부\n",
      "사용\n",
      "적\n",
      "합\n",
      "테\n",
      "스트\n",
      "Hid\n",
      "den\n",
      "Tag\n",
      "App\n",
      "설치\n",
      "후\n",
      ",\n",
      "정\n",
      "품\n",
      "인\n",
      "증\n",
      "확인\n",
      "Check\n"
     ]
    }
   ],
   "source": [
    "for id in labels[0].tolist()[:30]:\n",
    "  if id != -100:\n",
    "    print(processor.decode([id]))\n",
    "  else:\n",
    "    print(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<des>SOLUTION CARE 여드름성 피부 사용 적합 테스트 Hidden Tag App 설치 후, 정품인증 확인 Check the authenticity after installing Hidden Tag App 블랙헤드 유분개선 화이트헤드 Dr.Different VITAACNAL TX Night Cream 각질케어 * 임상으로 확인한 피부 유분 감소 비타아크날 TX 피부 각질 감소 나이트 크림 효과 화이트헤드 감소 블랙헤드 감소 피부 사용 인원 : 20명 (만15세~45세 여드름성피부 남녀), 개선, 적합/유분/블랙&화이트헤드/각질 시험기관 : 효능효과는 개인에 따라 (주)글로벌의학연구센터. 차이가 시험기간 : 있을 수 있습니다. 2020.09.28~2020.10.28 * * * 레티날 사용시 피부가 올라올 수 있습니다. 처음 사용하거나 피부가 섞어서 사용하시다가 점차 양을 따갑고 붉어질 수 민감하실 경우 크림에 있으며 각질이 소량 피부자극 테스트 완료 여드름성 피부 사용 적합 테스트 완료 처음 사용하거나 적응하면 바르고 민감하실 경우 사용하시기 매일 늘려 사용해주세요. 일주일에 세 번 바랍니다. 이내로 제조번호 및 화장품 책임판매업자 (주)다른코스메틱스 층(논현동, 다른타워) 화장품 제조업자 (주)에코먼트 경기도 산단로 63-5(모곡동) www.drdifferent.com MADE IN KOREA 평택시 서울특별시 강남구 학동로335 11, 12 8 809641 690685 > H0315 본 제품에 이상이 소비자상담실 : '소비자분쟁해결기준'에 있을 경우 의거 보상해 080-766-5252 공정거래위원회 고시 드립니다.</des><how>사용시의 1. 화장품 사용 사용부위가 붉은 반점, 이상 증상이나 부작용이 주의사항 시 또는 사용 후 부어오름 있는 경우 부위 등에는 사용을 직사광선에 또는 가려움증 전문의 등과 자제할 것 3. 의하여 등의 상담할 것. 2. 보관 및 취급 상처가 않는 곳에 보관할 것. 있는 시의 나) 고유의 노란색상이 주의할 것. 원료 주의사항 직사광선을 4. 함유된 수 있으니 어린이의 손이 피해서 천에 배어날 옷이나 닿지 보관할 것. 가) 사용방법 이제품은 밤에 쓰는 스킨케어 마지막 단계에서 완두콩 전체에 얇게 펴발라 흡수시켜 나이트트리트먼트 크기 줍니다. 크림입니다. 정도 덜어 얼굴</how><ing>전성분 정제수, 리스탈린셀룰로오스, 올리에이트, 글리세린, 유채스테롤, 1,2-헥산다이올, 마이크로크 폴리글리세릴-10 하이드로제네이티 콜레스테롤, 레틴 올레 세라마이드엔피, 스테아릭애씨드, 소듐하이알루로네이트, 다이소듐이디티에이 토코페롤, 폴리글루타믹애씨드, 드레시틴, 카프릴로일살리실릭애씨드, 알, 익애씨드,</ing><exp>2021.07.21제조 2023.07.20까지 사용기한 별도표기</exp><nm>비타아크날 TX 나이트 크림 더블 세트</nm><des>비타아크날 TX 나이트 크림 20g 완료* *여드름성</des><ing>베헤닐/옥틸도데실라우로일글루타메이트, 피토스테릴/</ing>\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_sequences[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pytorch Lightning Module Define**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DonutModelPLModule(pl.LightningModule):\n",
    "    def __init__(self, config, processor, model):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.processor = processor\n",
    "        self.model = model\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        pixel_values, labels, _ = batch\n",
    "        \n",
    "        outputs = self.model(pixel_values, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx, dataset_idx=0):\n",
    "        pixel_values, labels, answers = batch\n",
    "        batch_size = pixel_values.shape[0]\n",
    "\n",
    "        val_loss = self.model(pixel_values, labels=labels).loss\n",
    "\n",
    "        decoder_input_ids = torch.full((batch_size, 1), self.model.config.decoder_start_token_id, device=self.device)\n",
    "        \n",
    "        outputs = self.model.generate(pixel_values,\n",
    "                                   decoder_input_ids=decoder_input_ids,\n",
    "                                   max_length=CFG['MAX_LEN'],\n",
    "                                   early_stopping=True,\n",
    "                                   pad_token_id=self.processor.tokenizer.pad_token_id,\n",
    "                                   eos_token_id=self.processor.tokenizer.eos_token_id,\n",
    "                                   use_cache=True,\n",
    "                                   num_beams=1,\n",
    "                                   bad_words_ids=[[self.processor.tokenizer.unk_token_id]],\n",
    "                                   return_dict_in_generate=True,)\n",
    "    \n",
    "        predictions = []\n",
    "        for seq in self.processor.tokenizer.batch_decode(outputs.sequences):\n",
    "            seq = seq.replace(self.processor.tokenizer.eos_token, \"\").replace(self.processor.tokenizer.pad_token, \"\")\n",
    "            seq = re.sub(r\"<.*?>\", \"\", seq, count=1).strip()\n",
    "            predictions.append(seq)\n",
    "\n",
    "        scores = []\n",
    "        for pred, answer in zip(predictions, answers):\n",
    "            # pred = re.sub(r\"(?:(?<=>) | (?=\", \"\", answer, count=1)\n",
    "            # answer = answer.replace(self.processor.tokenizer.eos_token, \"\")\n",
    "            scores.append(edit_distance(pred, answer) / max(len(pred), len(answer)))\n",
    "\n",
    "            if self.config.get(\"verbose\", False) and len(scores) == 1:\n",
    "                print(f\"Prediction: {pred}\")\n",
    "                print(f\"    Answer: {answer}\")\n",
    "                print(f\" Normed ED: {scores[0]}\")\n",
    "        \n",
    "        self.log(\"val_loss\", val_loss)\n",
    "        self.log(\"val_edit_distance\", np.mean(scores))\n",
    "        \n",
    "        return pred \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "\n",
    "        num_total_steps = len(train_dataloader)*self.config.get('max_epochs')\n",
    "\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.config.get(\"lr\"), weight_decay=self.config.get(\"weight_decay\"))\n",
    "        scheduler = get_scheduler(\n",
    "                        self.config.get(\"sch_type\"),\n",
    "                        optimizer=optimizer,\n",
    "                        num_warmup_steps=math.ceil(num_total_steps*self.config.get(\"warmup_ratio\")),\n",
    "                        num_training_steps=num_total_steps,\n",
    "                    )\n",
    "        sch_config = {\n",
    "            \"scheduler\": scheduler,\n",
    "            \"interval\": \"step\",\n",
    "            \"name\": self.config.get(\"sch_type\") + \"_scheduler\",\n",
    "\t    }\n",
    "    \n",
    "        return [optimizer], [sch_config]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor, ModelCheckpoint\n",
    "import gc\n",
    "\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "\n",
    "def train(config=None):\n",
    "    with wandb.init(config=config):\n",
    "        config = wandb.config\n",
    "        wandb_logger = WandbLogger(log_model = \"all\")\n",
    "\n",
    "        training_args = {\n",
    "            \"max_epochs\":1,\n",
    "            \"val_check_interval\": 0.2,\n",
    "            \"check_val_every_n_epoch\": 1,\n",
    "            \"log_every_n_steps\": 100,\n",
    "            'grad_logging_step': 1000,\n",
    "            \"gradient_clip_val\": 1.0,\n",
    "            \"lr\": config.learning_rate,\n",
    "            \"weight_decay\": config.weight_decay,\n",
    "            \"accumulate_grad_batches\": 4,\n",
    "            \"num_nodes\": 1,\n",
    "            \"warmup_ratio\": config.warmup_ratio,\n",
    "            \"es_patience\": 1,\n",
    "            \"sch_type\": config.lr_scheduler_type,\n",
    "            \"verbose\": False,\n",
    "            }\n",
    "\n",
    "        model_module = DonutModelPLModule(training_args, processor, model_init())\n",
    "        \n",
    "        wandb_logger.watch(model_module, log='all', log_freq=training_args.get('grad_logging_step'), log_graph=False)\n",
    "        checkpoint_callback = ModelCheckpoint(monitor=\"val_edit_distance\", mode=\"min\", auto_insert_metric_name=True)\n",
    "        early_stop_callback = EarlyStopping(monitor=\"val_edit_distance\", patience=training_args.get('es_patience'), verbose=False, mode=\"min\")\n",
    "        lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "        log_predictions_callback = LogPredictionsCallback()\n",
    "\n",
    "        trainer = pl.Trainer(\n",
    "            accelerator=\"gpu\",\n",
    "            devices=1,\n",
    "            max_epochs=training_args.get(\"max_epochs\"),\n",
    "            val_check_interval=training_args.get(\"val_check_interval\"),\n",
    "            check_val_every_n_epoch=training_args.get(\"check_val_every_n_epoch\"),\n",
    "            gradient_clip_val=training_args.get(\"gradient_clip_val\"),\n",
    "            precision=16,\n",
    "            accumulate_grad_batches=training_args.get(\"accumulate_grad_batches\"),\n",
    "            num_sanity_val_steps=2,\n",
    "            logger=wandb_logger,\n",
    "            log_every_n_steps=training_args.get(\"log_every_n_steps\"),\n",
    "            callbacks=[early_stop_callback, lr_monitor, checkpoint_callback, log_predictions_callback],\n",
    "        )\n",
    "\n",
    "        trainer.fit(model_module, train_dataloader, val_dataloader)\n",
    "\n",
    "        del model_module\n",
    "        del wandb_logger\n",
    "        del checkpoint_callback\n",
    "        del early_stop_callback\n",
    "        del log_predictions_callback\n",
    "        del lr_monitor\n",
    "        del trainer\n",
    "            \n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'random',\n",
    "    'metric' : {\n",
    "        'name': 'val_edit_distance',\n",
    "        'goal': 'minimize',   \n",
    "        },\n",
    "    'parameters' : {\n",
    "        'learning_rate': {\n",
    "            'distribution': 'log_uniform_values',\n",
    "            'min': 1e-5,\n",
    "            'max': 1e-4,\n",
    "        },\n",
    "        'weight_decay': {\n",
    "            'distribution': 'q_uniform',\n",
    "            'min': 0,\n",
    "            'max': 1e-2,\n",
    "            'q': 0.001,\n",
    "        },\n",
    "        'warmup_ratio':{\n",
    "            'values': [0.1, 0.2]\n",
    "        },\n",
    "        'lr_scheduler_type':{\n",
    "            'values': ['inverse_sqrt', 'cosine']\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find ./experiment.ipynb.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: qeqll1ix\n",
      "Sweep URL: https://wandb.ai/2gnldud/DL2023_t5/sweeps/qeqll1ix\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: cw6hecok with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.00010239531115560212\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_scheduler_type: inverse_sqrt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_ratio: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.008\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find ./experiment.ipynb.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m2gnldud\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/2023-1_DL_TeamProject_t5/wandb/run-20230530_114354-cw6hecok</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/2gnldud/DL2023_t5/runs/cw6hecok' target=\"_blank\">comfy-sweep-1</a></strong> to <a href='https://wandb.ai/2gnldud/DL2023_t5' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/2gnldud/DL2023_t5/sweeps/qeqll1ix' target=\"_blank\">https://wandb.ai/2gnldud/DL2023_t5/sweeps/qeqll1ix</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/2gnldud/DL2023_t5' target=\"_blank\">https://wandb.ai/2gnldud/DL2023_t5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/2gnldud/DL2023_t5/sweeps/qeqll1ix' target=\"_blank\">https://wandb.ai/2gnldud/DL2023_t5/sweeps/qeqll1ix</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/2gnldud/DL2023_t5/runs/cw6hecok' target=\"_blank\">https://wandb.ai/2gnldud/DL2023_t5/runs/cw6hecok</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at naver-clova-ix/donut-base and are newly initialized because the shapes did not match:\n",
      "- decoder.model.decoder.embed_tokens.weight: found shape torch.Size([57525, 1024]) in the checkpoint and torch.Size([57539, 1024]) in the model instantiated\n",
      "- decoder.lm_head.weight: found shape torch.Size([57525, 1024]) in the checkpoint and torch.Size([57539, 1024]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                      | Params\n",
      "----------------------------------------------------\n",
      "0 | model | VisionEncoderDecoderModel | 201 M \n",
      "----------------------------------------------------\n",
      "201 M     Trainable params\n",
      "0         Non-trainable params\n",
      "201 M     Total params\n",
      "807.465   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  25%|██▍       | 208/833 [01:01<03:04,  3.39it/s, v_num=ecok]Prediction: <des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des>\n",
      "    Answer: <ing>【원료약품 및 분량】 · 유효성분 : 이 약</ing><des>【성상】 흰색의 원형 필름코팅정제</des><ing>1정 중 올메사르탄메독소밀(USP) 암로디핀베실산염(EP) (암로디핀으로5mg) 6.944mg 20mg ▪︎ 기타 첨가제 : 미결정셀룰로오스, 흰색(85F18422), 크로스카르멜로오스나트륨, 전호화전분, 스테아르산마그네슘, 콜로이드성이산화규소, 포비돈(K-30) 오파드라이II</ing>\n",
      " Normed ED: 0.9964774951076321\n",
      "Prediction: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "    Answer: <des>방부제 1 렌즈 착용시</des><how>【일회용 무보존제 점안액 사용법】 1. 뚜껑을 비틀어 돌린 후 주십시오. 당겨서 열어 2. 용기의 끝이 주의하여 점안합니다. 직접 눈에 닿지 않도록</how><des>※ 사용자 용량은 편의상 표시사항과 용기 동일 내 빈공간이 합니다. 존재하며 제품의 눈앤 R 점안액 0.5% (1회용) 하루종일 촉촉 하게 제조번호 21019</des><exp>사용기한 2023.03.09</exp><des>:</des><exp>:</exp><des>회용</des>\n",
      " Normed ED: 1.0\n",
      "Prediction: <des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des>\n",
      "    Answer: <des>188630 806109 8</des>\n",
      " Normed ED: 0.9980430528375733\n",
      "Prediction: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "    Answer: <des>일반의약품 정보 이 약을 사용하기 전 반드시 확인하세요. 첨부문서를</des><ing>【유효성분】 (100mL중) 세티리진염산염(BP) 100.0mg</ing><des>【효능 · 효과】 계절성 및 다년성 알레르기성 결막염, 두드러기, 피부소양증(피부가려움) 알레르기성 만성특발성(원인불명의) 비염(코염),</des><how>【용법 · 용량】 1. 성인 및 12세 이상의 소아 : 세티리진염산염으로서 (10mg)을 복용합니다. 1일 1회 10mL 2. 2~12세 미만의 소아 - 체중이 30kg이상인 경우 : 이 약으로서 1일 10mL (10mg) 복용합니다. - 체중이 30kg미만인 경우 : 이 약으로서 1일 5mL (5mg) 복용합니다. 3. 이상반응에 아침, 저녁으로 민감한 환자의 분할 복용합니다. 경우에는 4. 연령(나이), 합니다. 증상에 따라 적절히 증감 5. 중등도~중증(심한증상)의 장애)환자 : 투여 간격은 환자의 신장애(신장 신기능에 따라 조절되어야 합니다. 자세한 내용은 '첨부문서' 참조 【사용상의 주의사항】 1. 다음과 같은 사람은 이 약을 복용하지 마십시오. 1) 이 약 및 히드록시진 또는 피페라진 유도체에 있는 환자 2) 신부전 환자 3) 과민증 및 임부 그 및 병력이 임신 수유부 4) 하고 있을 2세 미만의 가능성이 영아(갓난아기) 있는 부인,</how>\n",
      " Normed ED: 0.9941291585127201\n",
      "Prediction: ,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,,\n",
      "    Answer: <des>Luxurious natural skin lotion infused with nourishing almond & kiwifruit oil & natural flowing soap infused with soothing chamomilee Fresh top notes of citrus and pear, layered over a subtle blend of marine, green florals and lily. Fine fragrance exclusive to Linden Leaves. Gentle daily care for all skin types. NATURAL HAND & BODY LOTION Ingredients INCI : aqua (eau), prunus amygdalus NATURAL HAND & BODY WASH Ingredients INCI : aqua (eau), lauryl glucoside, dulcis (sweet almond) oil, glyceryl stearate, isopropyl myristate, glycerin (vegetable), cetearyl alcohol, cetearyl benzyl alcohol (and) (and) sorbic acid, (Iemon) peel oil, (bergamot) peel oil, oil, citrus reticulata hydroxycitronellal*, methylpropional*, sodium stearoyl (kiwi) seed oil, leaf extract, phormium extract, citric acid. *fragrance component. tenax (harakeke) rosmarinus officinalis glutamate, actinidia linalool*, citronellol*, geraniol*, butylphenyl (tangerine) peel oil, citrus nobilis (mandarin) citrus aurantium bergamia parfum (fragrance), salicylic acid (and) olivate (and) sorbitan olivate, glycerin citrus limon peel citral*, limonene*, chinensis (rosemary) leaf sodium salicylic acid (and) parfum (fragrance), coco-sulphate, citrus limon (Iemon) glycerin (and) benzyl alcohol (and) sorbic acid, peel oil, MADE WITH LOVE IN NEW ZEALAND lindenleaves.com VEGAN</des><exp>12M</exp><nm>[제품명] 핸드앤바디워시앤로션세트 아쿠아릴리</nm><des>[책임판매업자] [용량] 300mlx2EA (주)린든리브즈코리아 / 서울시 송파구 충민로 66가든파이브 [해외제조원] New Zealand / Linden Leaves Limited 테크노관 6층 6050호</des><exp>[사용기한] 용기에 별도표기</exp><des>[제조번호] 용기에 별도표기 [핸드앤바디워시 아쿠아릴리]</des><ing>[전성분] 정제수, 라우릴글루코사이드, 소듐코코-설페이트, 만다린껍질오일, 올리브추출물, 벤질알코올, 하이드록시시트로넬알, 시트릭애씨드, 살리실릭애씨드, 부틸페닐메틸프로피오날, 향료, 글리세린, 소르빅애씨드, 리날룰, 레몬껍질오일, 시트로넬올, 올리브오일, 리모넨, 베르가모트껍질오일, 소듐클로라이드 마트리카리아꽃추출물, 필리핀오렌지껍질오일,</ing><des>[핸드앤바디로션 아쿠아릴리]</des><ing>【전성분] 정제수, 세테아릴올리베이트, 시트랄, 벤질알코올, 키위씨오일, 하이드록시시트로넬알, 글리세린, 솔비탄올리베이트, 제라니올, 살리실릭애씨드, 글리세릴스테아레이트에스이, 향료, 레몬껍질오일, 부틸페닐메틸프로피오날, 로즈마리잎추출물. 소르빅애씨드, 리날룰, 베르가모트껍질오일, 아이소프로필미리스테이트, 시트로넬올, 시트릭애씨드, 뉴질랜드삼추출물 리모넨, 필리핀오렌지껍질오일, 스위트아몬드오일, 소듐스테아로일글루타메이트, 세테아릴알코올, 만다린껍질오일,</ing><how>[사용상의 주의사항] 1) 가) 화장품 사용 시 부작용이 있는 경우 어린이의 손이 닿지 않는 곳에 보관할 것 또는 사용 후 전문의 등과 상담할 것 직사광선에 의하여 2) 나) 직사광선을 피해서 보관할 것 상처가 있는 부위 등에는 사용부위가 붉은 반점, 부어오름 또는 사용을 자제할 것 3) 보관 및 취급 시의 가려움증 등의 이상 증상이나 주의사항</how><des>\"본 제품에 이상이 있을 경우 공정거래위원회 고시 소비자분쟁 해결기준에 의해 보상해 드립니다.\" 플라스틱 HDPE</des>\n",
      " Normed ED: 0.9662019433882552\n",
      "Prediction: <des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des>\n",
      "    Answer: <ing>[성분명] 카프레이트, 폴리메칠메타크릴레이트, 세레 부틸렌글라이콜디카프릴레이트/디 신, 디페닐실록시페닐트리메치콘, 실리카, 옥 토크릴렌, 에칠헥실메톡시신나메이트, 트리 에칠헥사노인, 에칠헥실살리실레이트, 비 스-에칠헥실옥시페놀메톡시페닐트리아진, 합성왁스, 디메치콘, 디에칠아미노하이드록 시벤조일헥실벤조에이트, 레이트, 세이지잎수, 로즈마리잎수, 라벤더 디이소스테아릴말 수, 선백리향잎수, 두송열매수, 디메치콘/비 닐디메치콘크로스폴리머, 티타늄디옥사이드, 에칠렌/프로필렌코폴리머, 치콘, 쿼터늄-18벤토나이트, 향료, 신남알, 시트랄, 시트로넬올, 쿠마린, 리모넨, 유제놀, 파네솔, 리날룰 1,2-헥산디올, 메</ing>\n",
      " Normed ED: 0.9992172211350293\n",
      "Prediction: <des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des>\n",
      "    Answer: <nm>크로우 정</nm><des>로수바스타틴칼슘 10mg K-Inno Pharm</des><etc>혁신 형제약 기업 COMPANY PHARMACEUTICAL KOREA INNOVATIVE 보건복지부 ·</etc><des>28정 전문의약품 Daewon 대원제약</des>\n",
      " Normed ED: 0.9939334637964775\n",
      "Prediction: <des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des><des>\n",
      "    Answer: <ing>영양 · 기능 정보 1일 섭취량 : 1정(1,724mg) 1회 섭취량 당 함량 %영양성분기준치 1회 섭취량 당 함량 %영양성분기준치 열량 5kcal - 탄수화물 당류 1g미만 1g미만 0% 0% 0% 0g 0g 0% 단백질 지방 나트륨 비타민A 0mg 555㎍RE 0% 79% 비타민D 비타민E 비타민K 비타민B1 비타민B2 나이아신 판토텐산 비타민B6 10㎍ 100% 25mgα-TE 227% 70㎍ 100% 40mg 3,333% 35mg 2,500% 50mgNE 333% 70mg 1,400% 50mg 3,333% ※ %영양성분기준치 : 1일 영양성분기준치에 대한 비율 엽산 400㎍ 비타민B12 175㎍ 비오틴 150㎍ 100% 7,292% 500% 비타민C 철 아연 250mg 15mg 15mg 250% 125% 176% 구리 셀레늄 요오드 2mg 250% 100㎍ 182% 150㎍ 100% 망간 몰리브덴 크롬 칼슘 마그네슘 3.5mg 75㎍ 100㎍ 117% 300% 333% 100mg 14% 75mg 24% [비타민A] 어두운 곳에서 에너지 생성에 필요 판토텐산 지방, 탄수화물, 혈액생성에 필요, [비타민C, 비타민] 필요 [셀레늄] 칼슘과 인이 흡수되고 이용되는데 발생 위험감소에 도움을 줌 유해산소로부터 산소운반과 혈액생성에 필요 시각 적응을 위해 [비타민B6] 단백질 대사와 필요 단백질 및 아미노산 에너지 생성에 필요 [비타민B2, 이용에 나이아신] 체내 필요 [비오틴, [엽산] 세포와 유지하는데 필요 세포를 보호하는데 혈액의 호모시스테인 수준을 정상으로 유해산소로부터 항산화 작용을 하여 세포를 보호하고 유지하는데 필요 [비타민D] 골다공증 [철] 체내 [요오드] 필요, 갑상선 호르몬의 합성에 필요 필요, 형성과 유지에 뼈의 [아연] 정상적인 면역기능에 필요</ing>\n",
      " Normed ED: 0.9992172211350293\n",
      "Epoch 0:  50%|████▉     | 416/833 [03:23<03:24,  2.04it/s, v_num=ecok]Prediction: <des><des> </des><exp> </des><exp> </des><exp>  · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · ·\n",
      "    Answer: <ing>【원료약품 및 분량】 · 유효성분 : 이 약</ing><des>【성상】 흰색의 원형 필름코팅정제</des><ing>1정 중 올메사르탄메독소밀(USP) 암로디핀베실산염(EP) (암로디핀으로5mg) 6.944mg 20mg ▪︎ 기타 첨가제 : 미결정셀룰로오스, 흰색(85F18422), 크로스카르멜로오스나트륨, 전호화전분, 스테아르산마그네슘, 콜로이드성이산화규소, 포비돈(K-30) 오파드라이II</ing>\n",
      " Normed ED: 0.9850024189646831\n",
      "Prediction: <des><des><des><des> </des><exp><exp> </des><exp> </des><exp>\n",
      "    Answer: <des>방부제 1 렌즈 착용시</des><how>【일회용 무보존제 점안액 사용법】 1. 뚜껑을 비틀어 돌린 후 주십시오. 당겨서 열어 2. 용기의 끝이 주의하여 점안합니다. 직접 눈에 닿지 않도록</how><des>※ 사용자 용량은 편의상 표시사항과 용기 동일 내 빈공간이 합니다. 존재하며 제품의 눈앤 R 점안액 0.5% (1회용) 하루종일 촉촉 하게 제조번호 21019</des><exp>사용기한 2023.03.09</exp><des>:</des><exp>:</exp><des>회용</des>\n",
      " Normed ED: 0.8093525179856115\n",
      "Prediction: <des><des></des><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp>\n",
      "    Answer: <des>188630 806109 8</des>\n",
      " Normed ED: 0.9865771812080537\n",
      "Prediction: <des><des>  · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · · ·\n",
      "    Answer: <des>일반의약품 정보 이 약을 사용하기 전 반드시 확인하세요. 첨부문서를</des><ing>【유효성분】 (100mL중) 세티리진염산염(BP) 100.0mg</ing><des>【효능 · 효과】 계절성 및 다년성 알레르기성 결막염, 두드러기, 피부소양증(피부가려움) 알레르기성 만성특발성(원인불명의) 비염(코염),</des><how>【용법 · 용량】 1. 성인 및 12세 이상의 소아 : 세티리진염산염으로서 (10mg)을 복용합니다. 1일 1회 10mL 2. 2~12세 미만의 소아 - 체중이 30kg이상인 경우 : 이 약으로서 1일 10mL (10mg) 복용합니다. - 체중이 30kg미만인 경우 : 이 약으로서 1일 5mL (5mg) 복용합니다. 3. 이상반응에 아침, 저녁으로 민감한 환자의 분할 복용합니다. 경우에는 4. 연령(나이), 합니다. 증상에 따라 적절히 증감 5. 중등도~중증(심한증상)의 장애)환자 : 투여 간격은 환자의 신장애(신장 신기능에 따라 조절되어야 합니다. 자세한 내용은 '첨부문서' 참조 【사용상의 주의사항】 1. 다음과 같은 사람은 이 약을 복용하지 마십시오. 1) 이 약 및 히드록시진 또는 피페라진 유도체에 있는 환자 2) 신부전 환자 3) 과민증 및 임부 그 및 병력이 임신 수유부 4) 하고 있을 2세 미만의 가능성이 영아(갓난아기) 있는 부인,</how>\n",
      " Normed ED: 0.9297218155197657\n",
      "Prediction: <des>\n",
      "    Answer: <des>Luxurious natural skin lotion infused with nourishing almond & kiwifruit oil & natural flowing soap infused with soothing chamomilee Fresh top notes of citrus and pear, layered over a subtle blend of marine, green florals and lily. Fine fragrance exclusive to Linden Leaves. Gentle daily care for all skin types. NATURAL HAND & BODY LOTION Ingredients INCI : aqua (eau), prunus amygdalus NATURAL HAND & BODY WASH Ingredients INCI : aqua (eau), lauryl glucoside, dulcis (sweet almond) oil, glyceryl stearate, isopropyl myristate, glycerin (vegetable), cetearyl alcohol, cetearyl benzyl alcohol (and) (and) sorbic acid, (Iemon) peel oil, (bergamot) peel oil, oil, citrus reticulata hydroxycitronellal*, methylpropional*, sodium stearoyl (kiwi) seed oil, leaf extract, phormium extract, citric acid. *fragrance component. tenax (harakeke) rosmarinus officinalis glutamate, actinidia linalool*, citronellol*, geraniol*, butylphenyl (tangerine) peel oil, citrus nobilis (mandarin) citrus aurantium bergamia parfum (fragrance), salicylic acid (and) olivate (and) sorbitan olivate, glycerin citrus limon peel citral*, limonene*, chinensis (rosemary) leaf sodium salicylic acid (and) parfum (fragrance), coco-sulphate, citrus limon (Iemon) glycerin (and) benzyl alcohol (and) sorbic acid, peel oil, MADE WITH LOVE IN NEW ZEALAND lindenleaves.com VEGAN</des><exp>12M</exp><nm>[제품명] 핸드앤바디워시앤로션세트 아쿠아릴리</nm><des>[책임판매업자] [용량] 300mlx2EA (주)린든리브즈코리아 / 서울시 송파구 충민로 66가든파이브 [해외제조원] New Zealand / Linden Leaves Limited 테크노관 6층 6050호</des><exp>[사용기한] 용기에 별도표기</exp><des>[제조번호] 용기에 별도표기 [핸드앤바디워시 아쿠아릴리]</des><ing>[전성분] 정제수, 라우릴글루코사이드, 소듐코코-설페이트, 만다린껍질오일, 올리브추출물, 벤질알코올, 하이드록시시트로넬알, 시트릭애씨드, 살리실릭애씨드, 부틸페닐메틸프로피오날, 향료, 글리세린, 소르빅애씨드, 리날룰, 레몬껍질오일, 시트로넬올, 올리브오일, 리모넨, 베르가모트껍질오일, 소듐클로라이드 마트리카리아꽃추출물, 필리핀오렌지껍질오일,</ing><des>[핸드앤바디로션 아쿠아릴리]</des><ing>【전성분] 정제수, 세테아릴올리베이트, 시트랄, 벤질알코올, 키위씨오일, 하이드록시시트로넬알, 글리세린, 솔비탄올리베이트, 제라니올, 살리실릭애씨드, 글리세릴스테아레이트에스이, 향료, 레몬껍질오일, 부틸페닐메틸프로피오날, 로즈마리잎추출물. 소르빅애씨드, 리날룰, 베르가모트껍질오일, 아이소프로필미리스테이트, 시트로넬올, 시트릭애씨드, 뉴질랜드삼추출물 리모넨, 필리핀오렌지껍질오일, 스위트아몬드오일, 소듐스테아로일글루타메이트, 세테아릴알코올, 만다린껍질오일,</ing><how>[사용상의 주의사항] 1) 가) 화장품 사용 시 부작용이 있는 경우 어린이의 손이 닿지 않는 곳에 보관할 것 또는 사용 후 전문의 등과 상담할 것 직사광선에 의하여 2) 나) 직사광선을 피해서 보관할 것 상처가 있는 부위 등에는 사용부위가 붉은 반점, 부어오름 또는 사용을 자제할 것 3) 보관 및 취급 시의 가려움증 등의 이상 증상이나 주의사항</how><des>\"본 제품에 이상이 있을 경우 공정거래위원회 고시 소비자분쟁 해결기준에 의해 보상해 드립니다.\" 플라스틱 HDPE</des>\n",
      " Normed ED: 0.9978876214617659\n",
      "Prediction: <des>\n",
      "    Answer: <ing>[성분명] 카프레이트, 폴리메칠메타크릴레이트, 세레 부틸렌글라이콜디카프릴레이트/디 신, 디페닐실록시페닐트리메치콘, 실리카, 옥 토크릴렌, 에칠헥실메톡시신나메이트, 트리 에칠헥사노인, 에칠헥실살리실레이트, 비 스-에칠헥실옥시페놀메톡시페닐트리아진, 합성왁스, 디메치콘, 디에칠아미노하이드록 시벤조일헥실벤조에이트, 레이트, 세이지잎수, 로즈마리잎수, 라벤더 디이소스테아릴말 수, 선백리향잎수, 두송열매수, 디메치콘/비 닐디메치콘크로스폴리머, 티타늄디옥사이드, 에칠렌/프로필렌코폴리머, 치콘, 쿼터늄-18벤토나이트, 향료, 신남알, 시트랄, 시트로넬올, 쿠마린, 리모넨, 유제놀, 파네솔, 리날룰 1,2-헥산디올, 메</ing>\n",
      " Normed ED: 0.9943181818181818\n",
      "Prediction: <des><des><des><des></des><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp><exp>                                                                                                                                                             <des>  <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des> <des>  <des>  <des>     <des>   <des>     <des>\n",
      "    Answer: <nm>크로우 정</nm><des>로수바스타틴칼슘 10mg K-Inno Pharm</des><etc>혁신 형제약 기업 COMPANY PHARMACEUTICAL KOREA INNOVATIVE 보건복지부 ·</etc><des>28정 전문의약품 Daewon 대원제약</des>\n",
      " Normed ED: 0.9857187208941323\n",
      "Prediction: <des><des><des><des><des> <des>\n",
      "    Answer: <ing>영양 · 기능 정보 1일 섭취량 : 1정(1,724mg) 1회 섭취량 당 함량 %영양성분기준치 1회 섭취량 당 함량 %영양성분기준치 열량 5kcal - 탄수화물 당류 1g미만 1g미만 0% 0% 0% 0g 0g 0% 단백질 지방 나트륨 비타민A 0mg 555㎍RE 0% 79% 비타민D 비타민E 비타민K 비타민B1 비타민B2 나이아신 판토텐산 비타민B6 10㎍ 100% 25mgα-TE 227% 70㎍ 100% 40mg 3,333% 35mg 2,500% 50mgNE 333% 70mg 1,400% 50mg 3,333% ※ %영양성분기준치 : 1일 영양성분기준치에 대한 비율 엽산 400㎍ 비타민B12 175㎍ 비오틴 150㎍ 100% 7,292% 500% 비타민C 철 아연 250mg 15mg 15mg 250% 125% 176% 구리 셀레늄 요오드 2mg 250% 100㎍ 182% 150㎍ 100% 망간 몰리브덴 크롬 칼슘 마그네슘 3.5mg 75㎍ 100㎍ 117% 300% 333% 100mg 14% 75mg 24% [비타민A] 어두운 곳에서 에너지 생성에 필요 판토텐산 지방, 탄수화물, 혈액생성에 필요, [비타민C, 비타민] 필요 [셀레늄] 칼슘과 인이 흡수되고 이용되는데 발생 위험감소에 도움을 줌 유해산소로부터 산소운반과 혈액생성에 필요 시각 적응을 위해 [비타민B6] 단백질 대사와 필요 단백질 및 아미노산 에너지 생성에 필요 [비타민B2, 이용에 나이아신] 체내 필요 [비오틴, [엽산] 세포와 유지하는데 필요 세포를 보호하는데 혈액의 호모시스테인 수준을 정상으로 유해산소로부터 항산화 작용을 하여 세포를 보호하고 유지하는데 필요 [비타민D] 골다공증 [철] 체내 [요오드] 필요, 갑상선 호르몬의 합성에 필요 필요, 형성과 유지에 뼈의 [아연] 정상적인 면역기능에 필요</ing>\n",
      " Normed ED: 0.9944382647385984\n",
      "Epoch 0:  50%|████▉     | 416/833 [04:20<04:21,  1.60it/s, v_num=ecok]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  53%|█████▎    | 439/833 [04:42<04:13,  1.55it/s, v_num=ecok]"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=os.environ['WANDB_PROJECT'])\n",
    "wandb.agent(sweep_id, train, count=CFG['SWEEP_NUM'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

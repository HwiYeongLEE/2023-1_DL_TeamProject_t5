{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Packages Installation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %cd /home/2023-1_DL_TeamProject_t5\n",
    "# %pip install -r requirements.txt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Environment Variables Settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: WANDB_PROJECT=CM_CORD_DLt5\n",
      "env: WANDB_NOTEBOOK_NAME=./experiment.ipynb\n"
     ]
    }
   ],
   "source": [
    "%env WANDB_PROJECT=CM_CORD_DLt5\n",
    "%env WANDB_NOTEBOOK_NAME=./experiment.ipynb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import re\n",
    "from nltk import edit_distance\n",
    "\n",
    "from util import LogPredictionsCallback\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "# from pytorch_lightning.utilities import rank_zero_only\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from transformers import (\n",
    "    DonutProcessor,\n",
    "    VisionEncoderDecoderConfig,\n",
    "    VisionEncoderDecoderModel,\n",
    "    get_scheduler\n",
    ")\n",
    "\n",
    "import wandb\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device.type"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyperparameter Settings**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = {\n",
    "    'WORKING_DIR': \"/home/2023-1_DL_TeamProject_t5\",\n",
    "    'SEED':17,\n",
    "    'NUM_WORKERS':4,\n",
    "    'IMG_HEIGHT':800,\n",
    "    'IMG_WIDTH':600,\n",
    "    'MAX_LEN':1024,\n",
    "    'BATCH_SIZE':1,\n",
    "    'SAMPLING_RATE':0.5,\n",
    "    'VAL_SPLIT': 0.01,\n",
    "    'PIN_MEMORY': True,\n",
    "    'SWEEP_NUM': 8\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set Working Direcotry**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/2023-1_DL_TeamProject_t5\n"
     ]
    }
   ],
   "source": [
    "os.chdir(CFG['WORKING_DIR'])\n",
    "print(os.getcwd())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fix Seeds**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "seed_everything(CFG['SEED'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataset Building & Data Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_dict = {0:\"uni\", 1:\"nm\", 2:\"ing\", 3:\"exp\", 4:\"how\", 5:\"des\", 9:\"etc\"}\n",
    "\n",
    "class DonutDataset(Dataset):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        dataframe: pd.DataFrame,\n",
    "        max_length: int,\n",
    "        processor: DonutProcessor,\n",
    "        split: str = \"train\",\n",
    "        ignore_id: int = -100,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.max_length = max_length\n",
    "        self.split = split\n",
    "        self.ignore_id = ignore_id\n",
    "        self.dataframe = dataframe.reset_index(drop=True)\n",
    "        self.dataframe_length = len(self.dataframe)\n",
    "        self.processor = processor\n",
    "        self.gt_container = []\n",
    "        \n",
    "        for idx, sample in self.dataframe.iterrows():\n",
    "            ground_truth = self.get_gt_strings(eval(sample['texts']))\n",
    "            self.gt_container.append(ground_truth)\n",
    "\n",
    "    def get_gt_strings(self, ct):\n",
    "        \n",
    "        gt_string = \"\"\n",
    "        flag = 1\n",
    "        tp = -1\n",
    "        for i, item in enumerate(ct):\n",
    "            if flag:\n",
    "                gt_string = gt_string + f'<{type_dict[item[0]]}>'\n",
    "                tp = item[0]\n",
    "                flag = 0\n",
    "                gt_string = gt_string + f'{item[1]}'\n",
    "            \n",
    "            elif not flag:\n",
    "                gt_string = gt_string + f' {item[1]}'\n",
    "            \n",
    "            if i == len(ct)-1 or ct[i+1][0] != tp:\n",
    "                gt_string = gt_string + f'</{type_dict[item[0]]}>'\n",
    "                flag = 1\n",
    "        \n",
    "        return gt_string\n",
    "    \n",
    "    def __len__(self):\n",
    "        \n",
    "        return self.dataframe_length\n",
    "\n",
    "    def __getitem__(self, idx: int):\n",
    "\n",
    "        sample = self.dataframe.loc[idx]\n",
    "        image = Image.open(sample['image_path'])\n",
    "       \n",
    "        pixel_values = self.processor(image, random_padding=self.split == \"train\", return_tensors=\"pt\").pixel_values.squeeze()\n",
    "\n",
    "        target_sequence = self.gt_container[idx] \n",
    "        input_ids = self.processor.tokenizer(\n",
    "            target_sequence,\n",
    "            add_special_tokens=False,\n",
    "            max_length=self.max_length,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True,\n",
    "            return_tensors=\"pt\",\n",
    "        )[\"input_ids\"].squeeze(0)\n",
    "\n",
    "        labels = input_ids.clone()\n",
    "        labels[labels == self.processor.tokenizer.pad_token_id] = self.ignore_id  \n",
    "\n",
    "        return pixel_values, labels, target_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n"
     ]
    }
   ],
   "source": [
    "processor = DonutProcessor.from_pretrained(\"naver-clova-ix/donut-base\")\n",
    "processor.image_processor.size = {\"height\": CFG['IMG_HEIGHT'],\"width\": CFG['IMG_WIDTH']}\n",
    "added_tokens = [fr'<{x}>' for x in type_dict.values()] + [fr'</{x}>' for x in type_dict.values()]\n",
    "processor.tokenizer.add_tokens(added_tokens)\n",
    "\n",
    "donut_config = VisionEncoderDecoderConfig.from_pretrained(\"naver-clova-ix/donut-base\")\n",
    "donut_config.encoder.image_size = [CFG['IMG_HEIGHT'], CFG['IMG_WIDTH']]\n",
    "donut_config.decoder.max_length = CFG['MAX_LEN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():    \n",
    "    model = VisionEncoderDecoderModel.from_pretrained(\"naver-clova-ix/donut-base\", config=donut_config, ignore_mismatched_sizes=True)\n",
    "    model.decoder.resize_token_embeddings(len(processor.tokenizer))\n",
    "    model.config.pad_token_id = processor.tokenizer.pad_token_id\n",
    "    model.config.decoder_start_token_id = processor.tokenizer.convert_tokens_to_ids(['<s>'])[0]\n",
    "    return model\n",
    "\n",
    "model = model_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pad token ID: <pad>\n",
      "Decoder start token ID: <s>\n"
     ]
    }
   ],
   "source": [
    "print(\"Pad token ID:\", processor.decode([model.config.pad_token_id]))\n",
    "print(\"Decoder start token ID:\", processor.decode([model.config.decoder_start_token_id]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_val_df = pd.read_csv(\"./dataframes/train_annot_df.csv\")\n",
    "# test_df = pd.read_csv(\"./dataframes/test_annot_df.csv\")\n",
    "\n",
    "train_val_df = train_val_df[~train_val_df['image_path'].str.endswith('.png')]\n",
    "# test_df = test_df[~test_df['image_path'].str.endswith('.png')]\n",
    "\n",
    "train_df, val_df = train_test_split(train_val_df, test_size=CFG['VAL_SPLIT'], random_state=CFG['SEED'])\n",
    "\n",
    "train_df = train_df.sample(frac=CFG['SAMPLING_RATE'], random_state=CFG['SEED'], ignore_index=True)\n",
    "val_df = val_df.sample(frac=CFG['SAMPLING_RATE'], random_state=CFG['SEED'], ignore_index=True)\n",
    "\n",
    "train_dataset = DonutDataset(train_df, max_length=CFG['MAX_LEN'], processor=processor, split=\"train\")\n",
    "val_dataset = DonutDataset(val_df, max_length=CFG['MAX_LEN'], processor=processor, split=\"validation\")\n",
    "# test_dataset = DonutDataset(test_df, max_length=CFG['MAX_LEN'], processor=processor, split=\"test\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataloader Building**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=True, num_workers=CFG['NUM_WORKERS'], pin_memory=CFG['PIN_MEMORY'])\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=CFG['NUM_WORKERS'], pin_memory=CFG['PIN_MEMORY'])\n",
    "# test_dataloader = DataLoader(test_dataset, batch_size=CFG['BATCH_SIZE'], shuffle=False, num_workers=CFG['NUM_WORKERS'], pin_memory=CFG['PIN_MEMORY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 800, 600])\n"
     ]
    }
   ],
   "source": [
    "#Batch Verifying\n",
    "batch = next(iter(train_dataloader))\n",
    "pixel_values, labels, target_sequences = batch\n",
    "print(pixel_values.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ing>\n",
      "원\n",
      "료\n",
      "명\n",
      "및\n",
      "함\n",
      "량\n",
      "프로\n",
      "폴\n",
      "리스\n",
      "추출물\n",
      "(\n",
      "프\n",
      "로\n",
      "폴\n",
      "리스\n",
      "70%\n",
      ",\n",
      "\n",
      "덱\n",
      "스트\n",
      "린\n",
      "30%\n",
      ",\n",
      "호주\n",
      "산\n",
      ")\n",
      "41\n",
      ".\n",
      "95\n"
     ]
    }
   ],
   "source": [
    "for id in labels[0].tolist()[:30]:\n",
    "  if id != -100:\n",
    "    print(processor.decode([id]))\n",
    "  else:\n",
    "    print(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<ing>원료명 및 함량 프로폴리스추출물(프로폴리스 70%, 덱스트린 30%, 호주산) 41.95%, 비타민C(L-Ascorbic acid), 비타민E혼합제제(DL-α-토코페롤초산 염 50%, 변성전분), 말토덱스트린, 결정셀룰로 스, 베타글루칸분말, 대나무잎추출분말, 동결건조 로얄젤리분말, 산화아연, 건조효모(셀렌 0.2%), 황산동 *캡슐기제 : 젤라틴(소, 돼지), 정제수, 카라멜색소, 빙초산, 자당지방산에스테르 쇠고기, 돼지고기 함유</ing><how>섭취량 및 섭취방법/섭취 시 주의사항 *1일 1회, 1회 1캡슐씩 물과 함께 섭취 *과량 섭취 시 부작용이 있을 수 있으며 특 정원료에 알레르기가 있거나 질병치료나 약 물투여 중인 분들은 섭취 전 전문가와 상의 섭취하 프로 [프로폴리스추출물 제품] 섭취 사람은 제품은 경과된 유통기한이 나타내는 알레르기를 폴리스에 에 주의 지 마십시오. 하십시오.</how><des>우수건강기능식품제조기준 GMP 식품의약품안전처</des><etc>Best Family Friendly · · 가족친화 우수기업</etc><des>판매가격 33000원 PPC 007</des><ing>쌀단백분말(베트남산), 쌀발효분말(국산),</ing><etc>Management</etc>'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_sequences[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pytorch Lightning Module Define**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DonutModelPLModule(pl.LightningModule):\n",
    "    def __init__(self, config, processor, model):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.processor = processor\n",
    "        self.model = model\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        pixel_values, labels, _ = batch\n",
    "        \n",
    "        outputs = self.model(pixel_values, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        self.log(\"train_loss\", loss)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx, dataset_idx=0):\n",
    "        pixel_values, labels, answers = batch\n",
    "        batch_size = pixel_values.shape[0]\n",
    "\n",
    "        val_loss = self.model(pixel_values, labels=labels).loss\n",
    "\n",
    "        decoder_input_ids = torch.full((batch_size, 1), self.model.config.decoder_start_token_id, device=self.device)\n",
    "        \n",
    "        outputs = self.model.generate(pixel_values,\n",
    "                                   decoder_input_ids=decoder_input_ids,\n",
    "                                   max_length=CFG['MAX_LEN'],\n",
    "                                   early_stopping=True,\n",
    "                                   pad_token_id=self.processor.tokenizer.pad_token_id,\n",
    "                                   eos_token_id=self.processor.tokenizer.eos_token_id,\n",
    "                                   use_cache=True,\n",
    "                                   num_beams=1,\n",
    "                                   bad_words_ids=[[self.processor.tokenizer.unk_token_id]],\n",
    "                                   return_dict_in_generate=True,)\n",
    "    \n",
    "        predictions = []\n",
    "        for seq in self.processor.tokenizer.batch_decode(outputs.sequences):\n",
    "            seq = seq.replace(self.processor.tokenizer.eos_token, \"\").replace(self.processor.tokenizer.pad_token, \"\")\n",
    "            seq = re.sub(r\"<.*?>\", \"\", seq, count=1).strip()\n",
    "            predictions.append(seq)\n",
    "\n",
    "        scores = []\n",
    "        for pred, answer in zip(predictions, answers):\n",
    "            # pred = re.sub(r\"(?:(?<=>) | (?=\", \"\", answer, count=1)\n",
    "            # answer = answer.replace(self.processor.tokenizer.eos_token, \"\")\n",
    "            scores.append(edit_distance(pred, answer) / max(len(pred), len(answer)))\n",
    "\n",
    "            if self.config.get(\"verbose\", False) and len(scores) == 1:\n",
    "                print(f\"Prediction: {pred}\")\n",
    "                print(f\"    Answer: {answer}\")\n",
    "                print(f\" Normed ED: {scores[0]}\")\n",
    "        \n",
    "        self.log(\"val_loss\", val_loss)\n",
    "        self.log(\"val_edit_distance\", np.mean(scores))\n",
    "        \n",
    "        return [pred] \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "\n",
    "        num_total_steps = self.trainer.num_training_batches\n",
    "\n",
    "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.config.get(\"lr\"), weight_decay=self.config.get(\"weight_decay\"))\n",
    "        scheduler = get_scheduler(\n",
    "                        self.config.get(\"sch_type\"),\n",
    "                        optimizer=optimizer,\n",
    "                        num_warmup_steps=math.ceil(num_total_steps*self.config.get(\"warmup_ratio\")),\n",
    "                        num_training_steps=num_total_steps,\n",
    "                    )\n",
    "        sch_config = {\n",
    "            \"scheduler\": scheduler,\n",
    "            \"interval\": \"step\",\n",
    "            \"name\": self.config.get(\"sch_type\") + \"_scheduler\",\n",
    "\t    }\n",
    "    \n",
    "        return [optimizer], [sch_config]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define and Run Sweep**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor, ModelCheckpoint\n",
    "import gc\n",
    "\n",
    "torch.set_float32_matmul_precision(\"medium\")\n",
    "\n",
    "def train(config=None):\n",
    "    with wandb.init(config=config):\n",
    "        config = wandb.config\n",
    "        wandb_logger = WandbLogger(log_model = \"all\")\n",
    "\n",
    "        training_args = {\n",
    "            \"max_epochs\":1,\n",
    "            \"val_check_interval\": 0.25,\n",
    "            \"check_val_every_n_epoch\": 1,\n",
    "            \"log_every_n_steps\": 50,\n",
    "            'grad_logging_step': 100,\n",
    "            \"gradient_clip_val\": 1.0,\n",
    "            \"lr\": config.learning_rate,\n",
    "            \"weight_decay\": config.weight_decay,\n",
    "            \"accumulate_grad_batches\": 4,\n",
    "            \"num_nodes\": 1,\n",
    "            \"warmup_ratio\": config.warmup_ratio,\n",
    "            \"es_patience\": 1,\n",
    "            \"sch_type\": config.lr_scheduler_type,\n",
    "            \"verbose\": False,\n",
    "            }\n",
    "\n",
    "        model_module = DonutModelPLModule(training_args, processor, model_init())\n",
    "        \n",
    "        wandb_logger.watch(model_module, log='all', log_freq=training_args.get('grad_logging_step'), log_graph=False)\n",
    "        checkpoint_callback = ModelCheckpoint(monitor=\"val_edit_distance\", mode=\"min\", auto_insert_metric_name=True)\n",
    "        early_stop_callback = EarlyStopping(monitor=\"val_loss\", patience=training_args.get('es_patience'), verbose=False, mode=\"min\")\n",
    "        lr_monitor = LearningRateMonitor(logging_interval='step')\n",
    "        log_predictions_callback = LogPredictionsCallback()\n",
    "\n",
    "        trainer = pl.Trainer(\n",
    "            accelerator=\"gpu\",\n",
    "            devices=1,\n",
    "            max_epochs=training_args.get(\"max_epochs\"),\n",
    "            val_check_interval=training_args.get(\"val_check_interval\"),\n",
    "            check_val_every_n_epoch=training_args.get(\"check_val_every_n_epoch\"),\n",
    "            gradient_clip_val=training_args.get(\"gradient_clip_val\"),\n",
    "            precision=16,\n",
    "            accumulate_grad_batches=training_args.get(\"accumulate_grad_batches\"),\n",
    "            num_sanity_val_steps=0,\n",
    "            logger=wandb_logger,\n",
    "            log_every_n_steps=training_args.get(\"log_every_n_steps\"),\n",
    "            callbacks=[early_stop_callback, lr_monitor, checkpoint_callback, log_predictions_callback],\n",
    "        )\n",
    "\n",
    "        trainer.fit(model_module, train_dataloader, val_dataloader)\n",
    "\n",
    "        del model_module\n",
    "        del wandb_logger\n",
    "        del checkpoint_callback\n",
    "        del early_stop_callback\n",
    "        del log_predictions_callback\n",
    "        del lr_monitor\n",
    "        del trainer\n",
    "            \n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sweep_config = {\n",
    "    'method': 'random',\n",
    "    'metric' : {\n",
    "        'name': 'val_edit_distance',\n",
    "        'goal': 'minimize',   \n",
    "        },\n",
    "    'parameters' : {\n",
    "        'learning_rate': {\n",
    "            'distribution': 'log_uniform_values',\n",
    "            'min': 1e-5,\n",
    "            'max': 1e-4,\n",
    "        },\n",
    "        'weight_decay': {\n",
    "            'distribution': 'q_uniform',\n",
    "            'min': 0,\n",
    "            'max': 1e-2,\n",
    "            'q': 0.001,\n",
    "        },\n",
    "        'warmup_ratio':{\n",
    "            'values': [0.1, 0.2]\n",
    "        },\n",
    "        'lr_scheduler_type':{\n",
    "            'values': ['inverse_sqrt', 'cosine']\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find ./experiment.ipynb.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create sweep with ID: evskedf0\n",
      "Sweep URL: https://wandb.ai/2gnldud/CM_CORD_DLt5/sweeps/evskedf0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: j03ziswj with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 1.0718059468767836e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlr_scheduler_type: inverse_sqrt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \twarmup_ratio: 0.2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.009000000000000001\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m WANDB_NOTEBOOK_NAME should be a path to a notebook file, couldn't find ./experiment.ipynb.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33m2gnldud\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.15.3 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.2"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/2023-1_DL_TeamProject_t5/wandb/run-20230530_174701-j03ziswj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/2gnldud/CM_CORD_DLt5/runs/j03ziswj' target=\"_blank\">sparkling-sweep-1</a></strong> to <a href='https://wandb.ai/2gnldud/CM_CORD_DLt5' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/2gnldud/CM_CORD_DLt5/sweeps/evskedf0' target=\"_blank\">https://wandb.ai/2gnldud/CM_CORD_DLt5/sweeps/evskedf0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/2gnldud/CM_CORD_DLt5' target=\"_blank\">https://wandb.ai/2gnldud/CM_CORD_DLt5</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View sweep at <a href='https://wandb.ai/2gnldud/CM_CORD_DLt5/sweeps/evskedf0' target=\"_blank\">https://wandb.ai/2gnldud/CM_CORD_DLt5/sweeps/evskedf0</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/2gnldud/CM_CORD_DLt5/runs/j03ziswj' target=\"_blank\">https://wandb.ai/2gnldud/CM_CORD_DLt5/runs/j03ziswj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of VisionEncoderDecoderModel were not initialized from the model checkpoint at naver-clova-ix/donut-base and are newly initialized because the shapes did not match:\n",
      "- decoder.model.decoder.embed_tokens.weight: found shape torch.Size([57525, 1024]) in the checkpoint and torch.Size([57539, 1024]) in the model instantiated\n",
      "- decoder.lm_head.weight: found shape torch.Size([57525, 1024]) in the checkpoint and torch.Size([57539, 1024]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                      | Params\n",
      "----------------------------------------------------\n",
      "0 | model | VisionEncoderDecoderModel | 201 M \n",
      "----------------------------------------------------\n",
      "201 M     Trainable params\n",
      "0         Non-trainable params\n",
      "201 M     Total params\n",
      "807.465   Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  75%|███████▍  | 31245/41662 [3:31:10<1:10:24,  2.47it/s, v_num=iswj]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Ctrl + C detected. Stopping sweep.\n"
     ]
    }
   ],
   "source": [
    "sweep_id = wandb.sweep(sweep_config, project=os.environ['WANDB_PROJECT'])\n",
    "wandb.agent(sweep_id, train, count=CFG['SWEEP_NUM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
